{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:12:09.503222Z",
     "start_time": "2025-02-06T00:12:09.501751Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from lightgbm import LGBMRanker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from findhr.preprocess.example_mappings import MatchBinary, MatchOrdinal, MatchFeatureInclusion, MatchFeatureSet\n",
    "from findhr.preprocess.mapping import AttachMetadata, DetachMetadata, DerivedColumn\n",
    "from findhr.xai.counterfactual import dice_ml\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Helper Classes and Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "from findhr.preprocess.metadata import JSONMetadata\n",
    "\n",
    "# Define the metadata for the JDS dataset\n",
    "md_JDS = {\n",
    "    'qId': JSONMetadata(schema={'type': 'number'}),\n",
    "    'Occupation_j': JSONMetadata(schema={'type': 'string'}),\n",
    "    'Education_j': JSONMetadata(schema={'enum': ['No education', 'Degree', 'Bachelor D.', 'Master D.', 'PhD', 'Any']},\n",
    "                              attr_type='category'),\n",
    "    # 'Age_j': JSONMetadata(schema={'type': 'array',\n",
    "    #                               'prefixItems': [\n",
    "    #                                 { 'type': 'number' },\n",
    "    #                                 { 'type': 'number' },\n",
    "    #                               ],\n",
    "    #                               'items': False},\n",
    "    #                       ),\n",
    "    'Gender_j': JSONMetadata(schema={'enum': ['Male', 'Female', 'Non-binary', 'Any']},\n",
    "                             attr_type='category', attr_usage='sensitive'),\n",
    "    'Contract_j': JSONMetadata(schema={'enum': ['Remote', 'Hybrid', 'In presence']}),\n",
    "    'Nationality_j': JSONMetadata(schema={'type': 'string'}),\n",
    "    'Competences_j': JSONMetadata(schema={'type': \"array\", 'items': {'type': 'string'}}),\n",
    "    'Knowledge_j': JSONMetadata(schema={'type': \"array\", 'items': {'type': 'string'} }),\n",
    "    'Languages_j': JSONMetadata(schema={'type': \"array\", 'items': {'type': 'string'}}),\n",
    "    'Experience_j': JSONMetadata(schema={'type': 'number'}),\n",
    "}\n",
    "\n",
    "# Define the metadata for the CDS dataset\n",
    "md_CDS = {\n",
    "    'kId': JSONMetadata(schema={'type': 'integer'}),\n",
    "    'Occupation_c': JSONMetadata(schema={'type': 'string'}),\n",
    "    'Education_c': JSONMetadata(schema={'enum': ['No education', 'Degree', 'Bachelor D.', 'Master D.', 'PhD', 'Any']},\n",
    "                              attr_type='category'),\n",
    "    # 'Age_c': JSONMetadata(schema={'type': 'number'}),\n",
    "    'Gender_c': JSONMetadata(schema={'enum': ['Male', 'Female', 'Non-binary']},\n",
    "                             attr_type='category', attr_usage='sensitive'),\n",
    "    'Contract_c': JSONMetadata(schema={'enum': ['Remote', 'Hybrid', 'In presence', 'Any']}, attr_type='category'),\n",
    "    'Nationality_c': JSONMetadata(schema={'type': 'string'}),\n",
    "    'Competences_c': JSONMetadata(schema={'type': \"array\", 'items': {'type': 'string'}}),\n",
    "    'Knowledge_c': JSONMetadata(schema={'type': \"array\", 'items': {'type': 'string'}}),\n",
    "    'Experience_c': JSONMetadata(schema={'type': 'number'}),\n",
    "    'Languages_c': JSONMetadata(schema={'type': \"array\",'items': {'type': 'string'}}),\n",
    "}\n",
    "\n",
    "md_ADS = {\n",
    "    'rank': JSONMetadata(schema={'type': 'number', 'attr_usage':'target'}),\n",
    "    'score': JSONMetadata(schema={'type': 'number', 'attr_usage':'target'}),\n",
    "}\n",
    "md_CDS_JDS_ADS = {**md_CDS, **md_JDS, **md_ADS}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:12:09.536066Z",
     "start_time": "2025-02-06T00:12:09.505862Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class MacroVariables:\n",
    "    PATH = pathlib.Path(\"./code/DiCE_findhr/data\")\n",
    "\n",
    "    SUFFIX_DATASET = '1'  # '1' for demonstration, '2' for practice\n",
    "\n",
    "    FILENAME_CURRICULA = \"curricula{SUFFIX_DATASET}.csv\"\n",
    "    FILENAME_JOB_OFFERS = \"job_offers{SUFFIX_DATASET}.csv\"\n",
    "    FILENAME_ADS_FAIR = 'score{SUFFIX_DATASET}_fair.csv'\n",
    "    FILENAME_ADS_UNFAIR = 'score{SUFFIX_DATASET}_unfair.csv'\n",
    "\n",
    "    FILENAME_FITNESS_MATRIX_FAIR = \"fitness_mat{SUFFIX_DATASET}_fair.csv\"\n",
    "    FILENAME_FITNESS_MATRIX_UNFAIR = \"fitness_mat{SUFFIX_DATASET}_unfair.csv\"\n",
    "\n",
    "    FILEPATH_CURRICULA = PATH / FILENAME_CURRICULA.format(SUFFIX_DATASET=SUFFIX_DATASET)\n",
    "    FILEPATH_JOB_OFFERS = PATH / FILENAME_JOB_OFFERS.format(SUFFIX_DATASET=SUFFIX_DATASET)\n",
    "    FILEPATH_ADS_FAIR = PATH / FILENAME_ADS_FAIR.format(SUFFIX_DATASET=SUFFIX_DATASET)\n",
    "    FILEPATH_ADS_UNFAIR = PATH / FILENAME_ADS_UNFAIR.format(SUFFIX_DATASET=SUFFIX_DATASET)\n",
    "    FILEPATH_FITNESS_MATRIX_FAIR = PATH / FILENAME_FITNESS_MATRIX_FAIR.format(SUFFIX_DATASET=SUFFIX_DATASET)\n",
    "    FILEPATH_FITNESS_MATRIX_UNFAIR = PATH / FILENAME_FITNESS_MATRIX_UNFAIR.format(SUFFIX_DATASET=SUFFIX_DATASET)\n",
    "\n",
    "    TOP_K = 10\n",
    "\n",
    "    FAIR_DATA = True\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:12:09.541443Z",
     "start_time": "2025-02-06T00:12:09.508840Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def rank2relevance(df, top_k, col_rank):\n",
    "    return top_k + 1 - df[col_rank].values.ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:12:09.541583Z",
     "start_time": "2025-02-06T00:12:09.511155Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "# TRAIN_SIZE = 0.8\n",
    "VAL_SIZE = 0.25  # 0.25 x 0.8 = 0.2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:12:09.541635Z",
     "start_time": "2025-02-06T00:12:09.513636Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the Preprocessing pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# Helper function to convert columns of lists of values\n",
    "def convert_cols(x):\n",
    "    if isinstance(x, int) or isinstance(x, float) or isinstance(x, list):\n",
    "        return x\n",
    "    try:\n",
    "        x = ast.literal_eval(x)\n",
    "    finally:\n",
    "        return x\n",
    "\n",
    "# Helper function to convert columns of lists of values\n",
    "def rank2relevance(df, top_k, col_rank):\n",
    "    return top_k + 1 - df[col_rank].values.ravel()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:12:09.541687Z",
     "start_time": "2025-02-06T00:12:09.515808Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def load_dataset(fair_data=True):\n",
    "    # Read dataset\n",
    "    df_JDS = pd.read_csv(MacroVariables.FILEPATH_JOB_OFFERS,  # converters for columns of lists of values\n",
    "                         converters={c:convert_cols for c in [\"Age_j\", \"Competences_j\", \"Knowledge_j\", \"Languages_j\"]})\n",
    "    df_CDS = pd.read_csv(MacroVariables.FILEPATH_CURRICULA,  # converters for columns of lists of values\n",
    "                         converters={c:convert_cols for c in [\"Age_c\", \"Experience_c\", \"Competences_c\", \"Knowledge_c\", \"Languages_c\"]})\n",
    "    df_ADS_FAIR = pd.read_csv(MacroVariables.FILEPATH_ADS_FAIR)\n",
    "    df_ADS_UNFAIR = pd.read_csv(MacroVariables.FILEPATH_ADS_UNFAIR)\n",
    "\n",
    "    # Define subsets of columns\n",
    "    cols_id = ['qId', 'kId']\n",
    "    # Define the subset of columns of the HUDD dataset describing the candidate,\n",
    "    # which are used in the preprocessing+prediction pipeline\n",
    "    cols_c = ['Education_c', 'Age_c', 'Gender_c', 'Contract_c',\n",
    "              'Nationality_c', 'Competences_c', 'Knowledge_c', 'Languages_c',\n",
    "              'Experience_c']\n",
    "    cols_j = ['Education_j', 'Age_j', 'Gender_j',  'Contract_j', 'Nationality_j', 'Competences_j',\n",
    "              'Knowledge_j', 'Languages_j', 'Experience_j']\n",
    "    cols_pred_preprocess = cols_c + cols_j\n",
    "    cols_not_for_pred = ['Occupation_c', 'Occupation_j']\n",
    "    cols_sensitive = ['Gender_c']\n",
    "    col_target = ['score']\n",
    "\n",
    "    if fair_data:\n",
    "        # Merge CDS and JDS through ADS in a single dataframe\n",
    "        df_CDS_JDS = pd.merge(df_ADS_FAIR, df_JDS, on='qId')\n",
    "    else:\n",
    "        # Merge CDS and JDS through ADS in a single dataframe\n",
    "        df_CDS_JDS = pd.merge(df_ADS_UNFAIR, df_JDS, on='qId')\n",
    "\n",
    "    df_CDS_JDS = pd.merge(df_CDS, df_CDS_JDS, on='kId')\n",
    "    df_CDS_JDS = df_CDS_JDS[cols_id + [col for col in df_CDS_JDS if col not in cols_id+col_target] + col_target ]\n",
    "\n",
    "    return df_CDS_JDS, {'cols_pred_preprocess': cols_pred_preprocess,\n",
    "                        'cols_sensitive': cols_sensitive,\n",
    "                        'cols_id': cols_id,\n",
    "                        'cols_not_for_pred': cols_not_for_pred,\n",
    "                        'col_target': col_target}\n",
    "\n",
    "def build_matching_functions():\n",
    "    # Matching functions for pairs of job-candidate features\n",
    "    maps_matching = {\n",
    "         # MatchBinary: 1 = job value = candidate value OR job value is 'Any' OR candidate value is 'Any', 0 = otherwise\n",
    "        # (('qId',), ('qId',)): IdentityMapping(),\n",
    "        # (('kId',), ('kId',)): IdentityMapping(),\n",
    "        # (('rank',), ('rank',)): IdentityMapping(),\n",
    "        (('Contract_j', 'Contract_c'), ('fitness_Contract',)): MatchBinary(),\n",
    "        (('Gender_j', 'Gender_c'), ('fitness_Gender',)): MatchBinary(),\n",
    "        (('Nationality_j', 'Nationality_c'), ('fitness_Nationality',)): MatchBinary(),\n",
    "\n",
    "         # MatchOrdinal: 1 = job value >= candidate OR job value is 'Any', 0 = otherwise\n",
    "        (('Education_j', 'Education_c'), ('fitness_Education',)): MatchOrdinal(),\n",
    "        (('Experience_j', 'Experience_c'), ('fitness_Experience',)): MatchOrdinal(),\n",
    "\n",
    "         # MatchFeatureInclusion: 1 = candidate value in (job value(0,), >= job value(1,)) OR job value is 'Any', 0 = otherwise\n",
    "        # (('Age_j', 'Age_c'), ('fitness_Age',)): MatchFeatureInclusion(),\n",
    "\n",
    "         # MatchFeatureSet: 1 = fraction of job value that appear in candidate value\n",
    "        (('Languages_j', 'Languages_c'), ('fitness_Languages',)): MatchFeatureSet(),\n",
    "        (('Competences_j', 'Competences_c'), ('fitness_Competences',)): MatchFeatureSet(),\n",
    "        (('Knowledge_j', 'Knowledge_c'), ('fitness_Knowledge',)): MatchFeatureSet()\n",
    "    }\n",
    "    return maps_matching\n",
    "\n",
    "\n",
    "def build_fitness_matrix(df_CDS_JDS, cols_dict, fair_data=True):\n",
    "    maps_matching = build_matching_functions()\n",
    "\n",
    "    # Calculation as fit-transform preprocessing\n",
    "    pipeline_fitness = Pipeline(steps=[\n",
    "        (\"init\", AttachMetadata(md_CDS_JDS_ADS)),\n",
    "        (\"matching\", DerivedColumn(maps_matching)),\n",
    "        (\"end\", DetachMetadata())\n",
    "    ])\n",
    "\n",
    "    pipeline_fitness.fit(X=df_CDS_JDS)\n",
    "    fitness_matrix = pipeline_fitness.transform(X=df_CDS_JDS)\n",
    "    df_fitness_mat = fitness_matrix.copy(deep=True)\n",
    "    columns_keep = cols_dict['cols_id'] + \\\n",
    "                   [col for col in fitness_matrix if\n",
    "                    col.startswith('fitness_')] + cols_dict['cols_sensitive'] + cols_dict['col_target']\n",
    "\n",
    "    df_fitness_mat = df_fitness_mat[columns_keep]\n",
    "\n",
    "    # From scores, we can learn regressors; or we can produce ranks, and learn ranking models\n",
    "    df_fitness_mat['rank'] = df_fitness_mat.groupby(\"qId\")['score'].rank('dense', ascending=False)\n",
    "    df_fitness_mat['rank'] = df_fitness_mat['rank'].apply(lambda x: x if x <= MacroVariables.TOP_K else MacroVariables.TOP_K + 1)\n",
    "\n",
    "    return pipeline_fitness, df_fitness_mat"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:12:09.558269Z",
     "start_time": "2025-02-06T00:12:09.522120Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the ranking model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def data_split_FEDD(df_fitness_mat):\n",
    "    all_jobs = df_fitness_mat['qId'].unique()\n",
    "    train_jobs, test_jobs = train_test_split(all_jobs, test_size=0.2, random_state=42, shuffle=False)\n",
    "    train_jobs, val_jobs = train_test_split(train_jobs, test_size=0.25, random_state=42, shuffle=False)\n",
    "\n",
    "    # Build train, test and validation sets, ensuring they are sorted by qId, kId\n",
    "    df_train = df_fitness_mat[df_fitness_mat['qId'].isin(train_jobs)].sort_values([\"qId\", \"kId\"])\n",
    "    df_val = df_fitness_mat[df_fitness_mat['qId'].isin(val_jobs)].sort_values([\"qId\", \"kId\"])\n",
    "    df_test = df_fitness_mat[df_fitness_mat['qId'].isin(test_jobs)].sort_values([\"qId\", \"kId\"])\n",
    "\n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "\n",
    "def init(df_fitness_mat):\n",
    "    df_train, df_val, df_test = data_split_FEDD(df_fitness_mat)\n",
    "    # Define subsets of columns\n",
    "    cols_id = ['qId', 'kId']  # ids\n",
    "    cols_pred = [  # predictive\n",
    "        'fitness_Contract',\n",
    "        'fitness_Nationality',\n",
    "        'fitness_Education',\n",
    "        'fitness_Experience',\n",
    "        # 'fitness_Age',\n",
    "        'fitness_Gender',\n",
    "        'fitness_Languages',\n",
    "        'fitness_Competences',\n",
    "        'fitness_Knowledge']\n",
    "    cols_sensitive = ['Gender_c']  # sensitive attribute(s)\n",
    "    col_target = 'score'  # target value for ranking\n",
    "    col_rank = 'rank'  # rank value for ranking\n",
    "\n",
    "    cols_dict_FEDD = {'cols_id': cols_id,\n",
    "                      'cols_pred': cols_pred,\n",
    "                      'cols_sensitive': cols_sensitive,\n",
    "                      'col_target': col_target,\n",
    "                      'col_rank': col_rank}\n",
    "    # Define the ranking model\n",
    "    ranker = LGBMRanker(\n",
    "        objective=\"lambdarank\",\n",
    "        class_weight=\"balanced\",\n",
    "        boosting_type=\"gbdt\",\n",
    "        importance_type=\"gain\",\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        force_row_wise=True,\n",
    "        n_jobs=-1,  # max parallelism\n",
    "        verbose=-1  # no verbosity\n",
    "    )\n",
    "    return ranker, df_train, df_val, df_test, cols_dict_FEDD\n",
    "\n",
    "\n",
    "def train(ranker, df_train, df_val, cols_dict):\n",
    "    df_train_counts = df_train.groupby(\"qId\")[\"qId\"].count().to_numpy()\n",
    "    df_val_counts = df_val.groupby(\"qId\")[\"qId\"].count().to_numpy()\n",
    "\n",
    "    # Fitting ranker:\n",
    "    ranker.fit(\n",
    "        X=df_train[cols_dict['cols_pred']],\n",
    "        # LightGBM relevance is the higher the better\n",
    "        y=rank2relevance(df_train, MacroVariables.TOP_K, cols_dict['col_rank']),\n",
    "        group = df_train_counts,\n",
    "        eval_at = [MacroVariables.TOP_K],\n",
    "        # LightGBM relevance is the higher the better\n",
    "        eval_set =[(df_val[cols_dict['cols_pred']], rank2relevance(df_val, MacroVariables.TOP_K, cols_dict['col_rank']))],\n",
    "        eval_group =[df_val_counts]\n",
    "    )\n",
    "\n",
    "    return ranker\n",
    "\n",
    "\n",
    "def evaluate(ranker, df_test, cols_dict):\n",
    "    df_test_counts = df_test.groupby(\"qId\")[\"qId\"].count().to_numpy()\n",
    "    # Predicting ranker:\n",
    "    df_test['lambda'] = ranker.predict(df_test[cols_dict['cols_pred']])\n",
    "    df_test['pred_rank'] = df_test.groupby(\"qId\")['lambda'].rank('dense', ascending=False)\n",
    "    df_test['pred_rank'] = df_test['pred_rank'].apply(lambda x: x if x <= MacroVariables.TOP_K else MacroVariables.TOP_K + 1)\n",
    "\n",
    "    return df_test\n",
    "\n",
    "\n",
    "def ranking_pipeline(df_fitness_mat):\n",
    "    ranker, df_train, df_val, df_test, cols_dict_FEDD = init(df_fitness_mat)\n",
    "    ranker = train(ranker, df_train, df_val, cols_dict_FEDD)\n",
    "    df_test = evaluate(ranker, df_test, cols_dict_FEDD)\n",
    "    return ranker, df_test, cols_dict_FEDD"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:12:09.568962Z",
     "start_time": "2025-02-06T00:12:09.523966Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare the data for the counterfactual explanation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def define_cols_dict():\n",
    "    outcome_name_col = 'lambda'  # 'pred_rank'\n",
    "    continuous_features = ['fitness_Languages', 'fitness_Competences',\n",
    "                           'fitness_Knowledge']  # ['Age_c', 'Experience_c'],\n",
    "    categorical_features = ['fitness_Contract', 'fitness_Nationality', 'fitness_Education', 'fitness_Experience',\n",
    "                            # 'fitness_Age',\n",
    "                            'fitness_Gender']\n",
    "    cols_pred = continuous_features + categorical_features\n",
    "    return {'outcome_name_col': outcome_name_col, 'continuous_features': continuous_features,\n",
    "            'categorical_features': categorical_features, 'cols_pred': cols_pred}\n",
    "\n",
    "\n",
    "def extract_explicand_data_cf(job_id, candidate_position, df_test, ranker, cols_dict_FEDD, df_CDS_JDS):\n",
    "    # df_qId contains the data for the job qId\n",
    "    df_qId_FEDD = df_test[df_test['qId'] == job_id]\n",
    "    df_qId_FEDD['lambda'] = ranker.predict(df_qId_FEDD[cols_dict_FEDD['cols_pred']])\n",
    "    df_qId_FEDD['pred_rank'] = df_qId_FEDD.groupby(\"qId\")['lambda'].rank('dense', ascending=False)\n",
    "\n",
    "    exp_c_pred_rank = candidate_position\n",
    "\n",
    "    # Extract the explicand candidate kId\n",
    "    exp_c_kId = df_qId_FEDD.loc[df_qId_FEDD['pred_rank'] == exp_c_pred_rank, 'kId'].iloc[0]\n",
    "\n",
    "    # Isolate the candidates' profiles applying for the job qId\n",
    "    df_qId_HUDD = df_CDS_JDS[df_CDS_JDS['qId'] == job_id]\n",
    "\n",
    "    # Isolate the explicand candidate profile\n",
    "    exp_c_profile = df_CDS_JDS[df_CDS_JDS['kId'] == exp_c_kId]\n",
    "\n",
    "    exp_c = {'kId': exp_c_kId, 'profile': exp_c_profile}\n",
    "\n",
    "    cols_dict = define_cols_dict()\n",
    "\n",
    "    return df_qId_FEDD, df_qId_HUDD, exp_c, cols_dict\n",
    "\n",
    "\n",
    "def prepare_data_cf(df_qId_FEDD, cols_dict):\n",
    "\n",
    "    # Convert data types\n",
    "    df_qId_FEDD_pre = df_qId_FEDD[cols_dict['categorical_features']].astype('int').copy(deep=True)\n",
    "    df_qId_FEDD_pre[cols_dict['continuous_features']] = df_qId_FEDD[cols_dict['continuous_features']].astype('float').copy(deep=True)\n",
    "    df_qId_FEDD_pre[cols_dict['outcome_name_col']] = df_qId_FEDD[cols_dict['outcome_name_col']].copy(deep=True)\n",
    "    feature_dtypes = {col: df_qId_FEDD_pre[col].dtype for col in df_qId_FEDD_pre[cols_dict['cols_pred']].columns}\n",
    "\n",
    "    return df_qId_FEDD_pre, feature_dtypes\n",
    "\n",
    "\n",
    "def define_target(args, df_qId_FEDD):\n",
    "    # 'in_top_k' or 'out_top_k' depending on the candidate position\n",
    "    explicand_class = 'in_top_k' if args.candidate_position <= MacroVariables.TOP_K else 'out_top_k'\n",
    "\n",
    "    # target rank for counterfactual explanation\n",
    "    if args.target_rank:\n",
    "        tgt_cf_rank = args.target_rank\n",
    "        tgt_cf_score = df_qId_FEDD[df_qId_FEDD['pred_rank'] == tgt_cf_rank]['score'].iloc[0]\n",
    "        tgt_cf_candidate = df_qId_FEDD[df_qId_FEDD['pred_rank'] == tgt_cf_rank]\n",
    "\n",
    "    elif args.target_score:\n",
    "        tgt_cf_rank = None\n",
    "        tgt_cf_score = args.target_score\n",
    "        tgt_cf_candidate = None\n",
    "    else:\n",
    "        raise ValueError('Either target rank or target score must be provided')\n",
    "\n",
    "    return explicand_class, tgt_cf_rank, tgt_cf_score, tgt_cf_candidate\n",
    "\n",
    "\n",
    "def define_explainer_FEDD(ranker, df_qId_FEDD_pre, cols_dict_cf, feature_dtypes, explanation_method):\n",
    "    data_dice = dice_ml.Data(dataframe=df_qId_FEDD_pre[cols_dict_cf['cols_pred'] + [cols_dict_cf['outcome_name_col']]],\n",
    "                             continuous_features=cols_dict_cf['continuous_features'],\n",
    "                             categorical_features=cols_dict_cf['categorical_features'],\n",
    "                             outcome_name=cols_dict_cf['outcome_name_col'])\n",
    "\n",
    "    kwargs = {'top_k': MacroVariables.TOP_K, 'features_dtype': feature_dtypes}\n",
    "\n",
    "    model_dice = dice_ml.Model(model=ranker,\n",
    "                               backend={'explainer': 'dice_xgboost.DiceGenetic',\n",
    "                                        'model': \"lgbmranker_model.LGBMRankerModel\"},\n",
    "                               model_type=\"regressor\",\n",
    "                               # model_type=\"classifier\",\n",
    "                               kw_args=kwargs)\n",
    "\n",
    "    explainer = dice_ml.Dice(data_dice, model_dice, method=explanation_method)\n",
    "\n",
    "    return explainer, data_dice, model_dice\n",
    "\n",
    "\n",
    "def get_explanations_FEDD(df_qId_FEDD, exp_c, cols_dict_cf, explainer):\n",
    "\n",
    "    c_th_lambda = df_qId_FEDD[df_qId_FEDD['pred_rank'] == MacroVariables.TOP_K].iloc[0]['lambda']\n",
    "    explanations = explainer.generate_counterfactuals(exp_c['profile'][cols_dict_cf['cols_pred']],\n",
    "                                                      total_CFs=10,\n",
    "                                                      desired_range=[c_th_lambda, 100],\n",
    "                                                      # desired_class=\"opposite\",\n",
    "                                                      verbose=True)\n",
    "    return explanations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:12:09.569072Z",
     "start_time": "2025-02-06T00:12:09.536175Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "\n",
    "# The job id for which the counterfactual explanation is to be generated'\n",
    "# Valid values 160-199\n",
    "job_id = 163\n",
    "\n",
    "# The position of the candidate in the ranked list\n",
    "candidate_position = 9\n",
    "\n",
    "# Alternative ways to define the target of the explanation\n",
    "target_rank = MacroVariables.TOP_K\n",
    "target_score = 0.9\n",
    "\n",
    "explanation_method = 'genetic'\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:12:09.569123Z",
     "start_time": "2025-02-06T00:12:09.536346Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanations for the counterfactuals:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nc/fxn8v40951jf3zznr7vv6xx80000gn/T/ipykernel_69550/2851946975.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_qId_FEDD['lambda'] = ranker.predict(df_qId_FEDD[cols_dict_FEDD['cols_pred']])\n",
      "/var/folders/nc/fxn8v40951jf3zznr7vv6xx80000gn/T/ipykernel_69550/2851946975.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_qId_FEDD['pred_rank'] = df_qId_FEDD.groupby(\"qId\")['lambda'].rank('dense', ascending=False)\n",
      "/var/folders/nc/fxn8v40951jf3zznr7vv6xx80000gn/T/ipykernel_69550/2851946975.py:76: UserWarning: {'explainer': 'dice_xgboost.DiceGenetic', 'model': 'lgbmranker_model.LGBMRankerModel'} backend not in supported backends sklearn,TF1,TF2,PYT\n",
      "  model_dice = dice_ml.Model(model=ranker,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanations for the counterfactuals:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nc/fxn8v40951jf3zznr7vv6xx80000gn/T/ipykernel_69550/2851946975.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_qId_FEDD['lambda'] = ranker.predict(df_qId_FEDD[cols_dict_FEDD['cols_pred']])\n",
      "/var/folders/nc/fxn8v40951jf3zznr7vv6xx80000gn/T/ipykernel_69550/2851946975.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_qId_FEDD['pred_rank'] = df_qId_FEDD.groupby(\"qId\")['lambda'].rank('dense', ascending=False)\n",
      "/var/folders/nc/fxn8v40951jf3zznr7vv6xx80000gn/T/ipykernel_69550/2851946975.py:76: UserWarning: {'explainer': 'dice_xgboost.DiceGenetic', 'model': 'lgbmranker_model.LGBMRankerModel'} backend not in supported backends sklearn,TF1,TF2,PYT\n",
      "  model_dice = dice_ml.Model(model=ranker,\n"
     ]
    }
   ],
   "source": [
    "args = namedtuple('Args', ['target_rank', 'target_score', 'target_candidate'])\n",
    "\n",
    "args.target_rank = target_rank\n",
    "args.target_score = target_score\n",
    "args.candidate_position = candidate_position\n",
    "\n",
    "df_CDS_JDS, cols_dict_HUDD = load_dataset(fair_data=MacroVariables.FAIR_DATA)\n",
    "pipeline_fitness, df_fitness_mat = build_fitness_matrix(df_CDS_JDS, cols_dict_HUDD, fair_data=MacroVariables.FAIR_DATA)\n",
    "ranker, df_test, cols_dict_FEDD = ranking_pipeline(df_fitness_mat)\n",
    "# from cf_exp_FEDD import extract_explicand_data_cf, prepare_data_cf, define_target, define_explainer_FEDD, get_explanations_FEDD\n",
    "\n",
    "df_qId_FEDD, df_qId_HUDD, exp_c, cols_dict_cf = extract_explicand_data_cf(job_id, candidate_position, df_test, ranker, cols_dict_FEDD, df_CDS_JDS)\n",
    "# Convert data types\n",
    "df_qId_FEDD_pre, feature_dtypes = prepare_data_cf(df_qId_FEDD, cols_dict_cf)\n",
    "\n",
    "explicand_class, tgt_cf_rank, tgt_cf_score, tgt_cf_candidate = define_target(args, df_qId_FEDD)\n",
    "\n",
    "explainer, data_dice, model_dice = define_explainer_FEDD(ranker, df_qId_FEDD_pre, cols_dict_cf, feature_dtypes, explanation_method)\n",
    "print('Explanations for the counterfactuals:')\n",
    "explanations_FEDD = get_explanations_FEDD(df_qId_FEDD, exp_c, cols_dict_cf, explainer)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query instance (original outcome : -0.09421838819980621)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   fitness_Languages  fitness_Competences  fitness_Knowledge  \\\n0                0.0                  1.0           0.333333   \n\n   fitness_Contract  fitness_Nationality  fitness_Education  \\\n0                 1                    0                  1   \n\n   fitness_Experience  fitness_Gender    lambda  \n0                   1               1 -0.094218  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fitness_Languages</th>\n      <th>fitness_Competences</th>\n      <th>fitness_Knowledge</th>\n      <th>fitness_Contract</th>\n      <th>fitness_Nationality</th>\n      <th>fitness_Education</th>\n      <th>fitness_Experience</th>\n      <th>fitness_Gender</th>\n      <th>lambda</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.094218</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diverse Counterfactual set (new outcome: [-2.631657100755981, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": "   fitness_Languages  fitness_Competences  fitness_Knowledge  \\\n0                0.0                  1.0                0.3   \n0                0.0                  1.0                0.4   \n0                0.0                  1.0                0.2   \n0                0.0                  1.0                0.3   \n0                0.0                  1.0                0.3   \n0                0.0                  1.0                0.0   \n0                0.0                  1.0                0.7   \n0                0.0                  1.0                0.2   \n0                0.0                  1.0                0.5   \n0                0.0                  1.0                0.8   \n\n   fitness_Contract  fitness_Nationality  fitness_Education  \\\n0                 1                    0                  1   \n0                 1                    0                  1   \n0                 1                    0                  1   \n0                 1                    0                  0   \n0                 1                    1                  1   \n0                 1                    0                  1   \n0                 1                    0                  1   \n0                 1                    0                  0   \n0                 1                    0                  0   \n0                 1                    0                  1   \n\n   fitness_Experience  fitness_Gender    lambda  \n0                   1               1 -0.094218  \n0                   1               1 -0.094218  \n0                   1               1 -0.094218  \n0                   1               1 -0.094218  \n0                   1               1 -0.094218  \n0                   1               1  0.483927  \n0                   1               1 -0.094218  \n0                   1               1 -0.094218  \n0                   1               1 -0.094218  \n0                   1               1 -0.094218  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fitness_Languages</th>\n      <th>fitness_Competences</th>\n      <th>fitness_Knowledge</th>\n      <th>fitness_Contract</th>\n      <th>fitness_Nationality</th>\n      <th>fitness_Education</th>\n      <th>fitness_Experience</th>\n      <th>fitness_Gender</th>\n      <th>lambda</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.094218</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.094218</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.094218</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.094218</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.094218</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.483927</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.7</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.094218</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.094218</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.094218</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.8</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.094218</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(explanations_FEDD.visualize_as_dataframe())\n",
    "\n",
    "# explanations_FEDD.cf_examples_list[0].final_cfs_df.to_csv('final_cfs_df_FEDD.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:12:38.593989Z",
     "start_time": "2025-02-06T00:12:38.586867Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:12:11.591590Z",
     "start_time": "2025-02-06T00:12:09.499803Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
