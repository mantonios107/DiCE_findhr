{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from findhr.xai.counterfactual import dice_ml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import ast\n",
    "from findhr.preprocess.example_mappings import MatchBinary, MatchOrdinal, MatchFeatureSet, MatchFeatureInclusion\n",
    "from findhr.preprocess.mapping import AttachMetadata, DetachMetadata, DerivedColumn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMRanker\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:06:15.087184Z",
     "start_time": "2025-02-06T00:06:14.107702Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curricula1.csv           fitness_mat2_fair.csv    score1_fair.csv\r\n",
      "curricula2.csv           fitness_mat2_unfair.csv  score1_unfair.csv\r\n",
      "fitness_mat1_fair.csv    job_offers1.csv          score2_fair.csv\r\n",
      "fitness_mat1_unfair.csv  job_offers2.csv          score2_unfair.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls code/DiCE_findhr/data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:06:15.219496Z",
     "start_time": "2025-02-06T00:06:15.088386Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Helper Classes and Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class MacroVariables:\n",
    "    PATH = pathlib.Path(\"./code/DiCE_findhr/data\")\n",
    "\n",
    "    SUFFIX_DATASET = '1'  # '1' for demonstration, '2' for practice\n",
    "\n",
    "    FILENAME_CURRICULA = \"curricula{SUFFIX_DATASET}.csv\"\n",
    "    FILENAME_JOB_OFFERS = \"job_offers{SUFFIX_DATASET}.csv\"\n",
    "    FILENAME_ADS_FAIR = 'score{SUFFIX_DATASET}_fair.csv'\n",
    "    FILENAME_ADS_UNFAIR = 'score{SUFFIX_DATASET}_unfair.csv'\n",
    "\n",
    "    FILENAME_FITNESS_MATRIX_FAIR = \"fitness_mat{SUFFIX_DATASET}_fair.csv\"\n",
    "    FILENAME_FITNESS_MATRIX_UNFAIR = \"fitness_mat{SUFFIX_DATASET}_unfair.csv\"\n",
    "\n",
    "    FILEPATH_CURRICULA = PATH / FILENAME_CURRICULA.format(SUFFIX_DATASET=SUFFIX_DATASET)\n",
    "    FILEPATH_JOB_OFFERS = PATH / FILENAME_JOB_OFFERS.format(SUFFIX_DATASET=SUFFIX_DATASET)\n",
    "    FILEPATH_ADS_FAIR = PATH / FILENAME_ADS_FAIR.format(SUFFIX_DATASET=SUFFIX_DATASET)\n",
    "    FILEPATH_ADS_UNFAIR = PATH / FILENAME_ADS_UNFAIR.format(SUFFIX_DATASET=SUFFIX_DATASET)\n",
    "    FILEPATH_FITNESS_MATRIX_FAIR = PATH / FILENAME_FITNESS_MATRIX_FAIR.format(SUFFIX_DATASET=SUFFIX_DATASET)\n",
    "    FILEPATH_FITNESS_MATRIX_UNFAIR = PATH / FILENAME_FITNESS_MATRIX_UNFAIR.format(SUFFIX_DATASET=SUFFIX_DATASET)\n",
    "\n",
    "    TOP_K = 10\n",
    "\n",
    "    FAIR_DATA = True\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:06:15.223343Z",
     "start_time": "2025-02-06T00:06:15.222187Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from findhr.preprocess.metadata import JSONMetadata\n",
    "\n",
    "# Define the metadata for the JDS dataset\n",
    "md_JDS = {\n",
    "    'qId': JSONMetadata(schema={'type': 'number'}),\n",
    "    'Occupation_j': JSONMetadata(schema={'type': 'string'}),\n",
    "    'Education_j': JSONMetadata(schema={'enum': ['No education', 'Degree', 'Bachelor D.', 'Master D.', 'PhD', 'Any']},\n",
    "                              attr_type='category'),\n",
    "    # 'Age_j': JSONMetadata(schema={'type': 'array',\n",
    "    #                               'prefixItems': [\n",
    "    #                                 { 'type': 'number' },\n",
    "    #                                 { 'type': 'number' },\n",
    "    #                               ],\n",
    "    #                               'items': False},\n",
    "    #                       ),\n",
    "    'Gender_j': JSONMetadata(schema={'enum': ['Male', 'Female', 'Non-binary', 'Any']},\n",
    "                             attr_type='category', attr_usage='sensitive'),\n",
    "    'Contract_j': JSONMetadata(schema={'enum': ['Remote', 'Hybrid', 'In presence']}),\n",
    "    'Nationality_j': JSONMetadata(schema={'type': 'string'}),\n",
    "    'Competences_j': JSONMetadata(schema={'type': \"array\", 'items': {'type': 'string'}}),\n",
    "    'Knowledge_j': JSONMetadata(schema={'type': \"array\", 'items': {'type': 'string'} }),\n",
    "    'Languages_j': JSONMetadata(schema={'type': \"array\", 'items': {'type': 'string'}}),\n",
    "    'Experience_j': JSONMetadata(schema={'type': 'number'}),\n",
    "}\n",
    "\n",
    "# Define the metadata for the CDS dataset\n",
    "md_CDS = {\n",
    "    'kId': JSONMetadata(schema={'type': 'integer'}),\n",
    "    'Occupation_c': JSONMetadata(schema={'type': 'string'}),\n",
    "    'Education_c': JSONMetadata(schema={'enum': ['No education', 'Degree', 'Bachelor D.', 'Master D.', 'PhD', 'Any']},\n",
    "                              attr_type='category'),\n",
    "    # 'Age_c': JSONMetadata(schema={'type': 'number'}),\n",
    "    'Gender_c': JSONMetadata(schema={'enum': ['Male', 'Female', 'Non-binary']},\n",
    "                             attr_type='category', attr_usage='sensitive'),\n",
    "    'Contract_c': JSONMetadata(schema={'enum': ['Remote', 'Hybrid', 'In presence', 'Any']}, attr_type='category'),\n",
    "    'Nationality_c': JSONMetadata(schema={'type': 'string'}),\n",
    "    'Competences_c': JSONMetadata(schema={'type': \"array\", 'items': {'type': 'string'}}),\n",
    "    'Knowledge_c': JSONMetadata(schema={'type': \"array\", 'items': {'type': 'string'}}),\n",
    "    'Experience_c': JSONMetadata(schema={'type': 'number'}),\n",
    "    'Languages_c': JSONMetadata(schema={'type': \"array\",'items': {'type': 'string'}}),\n",
    "}\n",
    "\n",
    "md_ADS = {\n",
    "    'rank': JSONMetadata(schema={'type': 'number', 'attr_usage':'target'}),\n",
    "    'score': JSONMetadata(schema={'type': 'number', 'attr_usage':'target'}),\n",
    "}\n",
    "md_CDS_JDS_ADS = {**md_CDS, **md_JDS, **md_ADS}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:06:15.229712Z",
     "start_time": "2025-02-06T00:06:15.228346Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def rank2relevance(df, top_k, col_rank):\n",
    "    return top_k + 1 - df[col_rank].values.ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:06:15.232768Z",
     "start_time": "2025-02-06T00:06:15.231704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Define hyperparameters for the data split\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "VAL_SIZE = 0.25 # 0.25 x 0.8 = 0.2\n",
    "\n",
    "RANDOM_STATE = 42"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:06:15.234562Z",
     "start_time": "2025-02-06T00:06:15.233605Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Loading and Splitting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def data_split(df_qId_kId):\n",
    "    all_jobs = df_qId_kId['qId'].unique()\n",
    "    train_jobs, test_jobs = train_test_split(all_jobs, test_size=TEST_SIZE, random_state=RANDOM_STATE, shuffle=False)\n",
    "    train_jobs, val_jobs = train_test_split(train_jobs, test_size=VAL_SIZE, random_state=RANDOM_STATE, shuffle=False)\n",
    "\n",
    "    # Build train, test and validation sets, ensuring they are sorted by qId, kId\n",
    "    df_train = df_qId_kId[df_qId_kId['qId'].isin(train_jobs)].sort_values([\"qId\", \"kId\"])\n",
    "    df_val = df_qId_kId[df_qId_kId['qId'].isin(val_jobs)].sort_values([\"qId\", \"kId\"])\n",
    "    df_test = df_qId_kId[df_qId_kId['qId'].isin(test_jobs)].sort_values([\"qId\", \"kId\"])\n",
    "\n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "\n",
    "def convert_cols_mod(x):\n",
    "    if isinstance(x, int) or isinstance(x, float):\n",
    "        return x\n",
    "    elif isinstance(x, list):\n",
    "        return tuple(x)\n",
    "    else:\n",
    "        try:\n",
    "            x = ast.literal_eval(x)\n",
    "        finally:\n",
    "            if isinstance(x, list):\n",
    "                return tuple(x)\n",
    "            return x\n",
    "\n",
    "def load_dataset(fair_data=True):\n",
    "    # Read dataset\n",
    "    df_JDS = pd.read_csv(MacroVariables.FILEPATH_JOB_OFFERS,  # converters for columns of lists of values\n",
    "                         converters={c: convert_cols_mod for c in [\n",
    "                             \"Age_j\",\n",
    "                             \"Competences_j\", \"Knowledge_j\", \"Languages_j\"]})\n",
    "\n",
    "    df_CDS = pd.read_csv(MacroVariables.FILEPATH_CURRICULA,  # converters for columns of lists of values\n",
    "                         converters={c: convert_cols_mod for c in [\n",
    "                             \"Age_c\",\n",
    "                             \"Experience_c\", \"Competences_c\", \"Knowledge_c\", \"Languages_c\"]})\n",
    "    # df_CDS = df_CDS.iloc[:20]\n",
    "    # df_JDS = df_JDS.iloc[:20]\n",
    "    df_CDS.drop(columns=['Age_c'], inplace=True)\n",
    "    df_JDS.drop(columns=['Age_j'], inplace=True)\n",
    "\n",
    "    df_ADS_FAIR = pd.read_csv(MacroVariables.FILEPATH_ADS_FAIR)\n",
    "    df_ADS_UNFAIR = pd.read_csv(MacroVariables.FILEPATH_ADS_UNFAIR)\n",
    "\n",
    "\n",
    "    cols_dict_HUDD = define_cols_dict_HUDD()\n",
    "\n",
    "\n",
    "    if fair_data:\n",
    "        # Merge CDS and JDS through ADS in a single dataframe\n",
    "        df_CDS_JDS = pd.merge(df_ADS_FAIR, df_JDS, on='qId')\n",
    "    else:\n",
    "        # Merge CDS and JDS through ADS in a single dataframe\n",
    "        df_CDS_JDS = pd.merge(df_ADS_UNFAIR, df_JDS, on='qId')\n",
    "\n",
    "    df_CDS_JDS = pd.merge(df_CDS, df_CDS_JDS, on='kId')\n",
    "    df_CDS_JDS = df_CDS_JDS[cols_dict_HUDD['cols_id'] + [col for col in df_CDS_JDS if col not in cols_dict_HUDD['cols_id']+ cols_dict_HUDD['col_target']] +\n",
    "                            cols_dict_HUDD['col_target']]\n",
    "    df_CDS_JDS[cols_dict_HUDD['col_rank']] = np.minimum(df_CDS_JDS.groupby(\"qId\")[cols_dict_HUDD['col_target']].rank('dense', ascending=False), MacroVariables.TOP_K + 1)\n",
    "\n",
    "    # dict_multilabelbinarizer = {}\n",
    "    # for col in cols_dict_HUDD['setlist_features']:\n",
    "    #     df_CDS_JDS, mlb = convert_skills(df_CDS_JDS, col)\n",
    "    #     dict_multilabelbinarizer[col] = mlb\n",
    "\n",
    "    # TODO: Change the original data\n",
    "    return df_CDS_JDS, cols_dict_HUDD# , dict_multilabelbinarizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:06:15.278850Z",
     "start_time": "2025-02-06T00:06:15.277544Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def define_cols_dict_HUDD():\n",
    "    \"\"\"\n",
    "    Define the columns of the HUDD dataset\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    cols_dict_HUDD: dict\n",
    "        Dictionary with the columns of the HUDD dataset\n",
    "    \"\"\"\n",
    "    # Define subsets of columns\n",
    "    cols_id = ['qId', 'kId']\n",
    "\n",
    "    # Define the subset of columns of the HUDD dataset describing the candidate,\n",
    "    # which are used in the preprocessing+prediction pipeline\n",
    "    cols_c = ['Education_c',\n",
    "              'Age_c',\n",
    "              'Gender_c', 'Contract_c',\n",
    "              'Nationality_c', 'Competences_c', 'Knowledge_c', 'Languages_c',\n",
    "              'Experience_c']\n",
    "    cols_j = ['Education_j',\n",
    "              # 'Age_j',\n",
    "              'Gender_j',  'Contract_j', 'Nationality_j', 'Competences_j',\n",
    "              'Knowledge_j', 'Languages_j', 'Experience_j']\n",
    "    cols_pred_preprocess = cols_c + cols_j\n",
    "    cols_not_for_pred = ['Occupation_c', 'Occupation_j']\n",
    "    cols_sensitive = ['Gender_c']\n",
    "    col_target = ['score']\n",
    "    col_rank = ['rank']\n",
    "\n",
    "    # Define the subset of columns of the HUDD dataset for the counterfactual explanation\n",
    "    outcome_name_col = 'lambda'  # 'pred_rank'\n",
    "    continuous_features = [\n",
    "        # 'Age_c',\n",
    "        'Experience_c', 'Experience_j']  # ['Age_c', 'Experience_c'],\n",
    "    categorical_features = ['Education_c', 'Gender_c', 'Contract_c', 'Nationality_c',\n",
    "                            # 'Competences_c', 'Knowledge_c', 'Languages_c',\n",
    "                            'Education_j', 'Gender_j', 'Contract_j', 'Nationality_j',\n",
    "                            # 'Competences_j', 'Knowledge_j', 'Languages_j',\n",
    "                            # 'Age_j'\n",
    "                            ]\n",
    "    setlist_features = ['Competences_c', 'Knowledge_c', 'Languages_c',\n",
    "                        'Competences_j', 'Knowledge_j', 'Languages_j',\n",
    "                        # 'Age_j'\n",
    "                        ]\n",
    "    cols_pred = ['Education_c',\n",
    "                 # 'Age_c',\n",
    "                 'Gender_c',\n",
    "       'Contract_c', 'Nationality_c', 'Competences_c', 'Knowledge_c',\n",
    "       'Languages_c', 'Experience_c', 'Education_j',\n",
    "                 # 'Age_j',\n",
    "       'Gender_j', 'Contract_j', 'Nationality_j', 'Competences_j',\n",
    "       'Knowledge_j', 'Languages_j', 'Experience_j']\n",
    "\n",
    "    # continuous_features + categorical_features\n",
    "    return {'outcome_name_col': outcome_name_col, 'continuous_features': continuous_features,\n",
    "            'categorical_features': categorical_features, \"setlist_features\": setlist_features,\n",
    "            'cols_pred': cols_pred,\n",
    "            'cols_id': cols_id, 'cols_sensitive': cols_sensitive, 'col_target': col_target, 'col_rank': col_rank,\n",
    "            'cols_pred_preprocess': cols_pred_preprocess, 'cols_not_for_pred': cols_not_for_pred}\n",
    "\n",
    "def define_cols_dict_FEDD():\n",
    "    \"\"\"\n",
    "    Define the columns of the FEDD dataset\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    cols_dict_FEDD: dict\n",
    "        Dictionary with the columns of the FEDD dataset\n",
    "    \"\"\"\n",
    "\n",
    "    outcome_name_col = 'lambda'  # 'pred_rank'\n",
    "    continuous_features = ['fitness_Languages', 'fitness_Competences',\n",
    "                           'fitness_Knowledge']  # ['Age_c', 'Experience_c'],\n",
    "    categorical_features = ['fitness_Contract', 'fitness_Nationality', 'fitness_Education', 'fitness_Experience',\n",
    "                            #'fitness_Age',\n",
    "                            'fitness_Gender']\n",
    "    cols_pred = continuous_features + categorical_features\n",
    "\n",
    "    cols_id = ['qId', 'kId']  # ids\n",
    "    cols_sensitive = ['Gender_c']  # sensitive attribute(s)\n",
    "    col_target = 'score'  # target value for ranking\n",
    "    col_rank = 'rank'  # rank value for ranking\n",
    "\n",
    "    return {'outcome_name_col': outcome_name_col, 'continuous_features': continuous_features,\n",
    "            'categorical_features': categorical_features, 'cols_pred': cols_pred,\n",
    "            'cols_id': cols_id, 'cols_sensitive': cols_sensitive, 'col_target': col_target, 'col_rank': col_rank}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:06:15.283127Z",
     "start_time": "2025-02-06T00:06:15.279104Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class SuperRankerPipeline:\n",
    "\n",
    "    def __init__(self, pipeline, ranker, cols_dict_FEDD): # steps, *, memory=None, verbose=False):\n",
    "        self.pipeline = pipeline\n",
    "        self.ranker = ranker\n",
    "        self.cols_dict_FEDD = cols_dict_FEDD\n",
    "\n",
    "    def predict(self, X):\n",
    "        # params_pipeline = {k: v for k, v in params.items() if k in self.pipeline.get_params().keys()}\n",
    "        _intermediate = self.pipeline.transform(X)\n",
    "        # print('_intermediate', _intermediate)\n",
    "        # _intermediate.drop(columns=['qId', 'kId'], inplace=True)\n",
    "        return self.ranker.predict(_intermediate[self.cols_dict_FEDD['cols_pred']])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:06:15.285119Z",
     "start_time": "2025-02-06T00:06:15.284427Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def extract_explicand_data_cf(job_id, exp_c_pred_rank, pipeline_fitness, df_CDS_JDS):\n",
    "    # df_qId contains the data for the job qId\n",
    "\n",
    "    # Isolate the candidates' profiles applying for the job qId\n",
    "    df_qId_HUDD = df_CDS_JDS[df_CDS_JDS['qId'] == job_id]\n",
    "\n",
    "    # Extract the explicand candidate kId\n",
    "    exp_c_kId = df_qId_HUDD.loc[df_qId_HUDD['pred_rank'] == exp_c_pred_rank, 'kId'].iloc[0]\n",
    "\n",
    "    # Isolate the explicand candidate profile\n",
    "    exp_c_profile = df_CDS_JDS[df_CDS_JDS['kId'] == exp_c_kId]\n",
    "\n",
    "    exp_c_fitness = pipeline_fitness.transform(exp_c_profile)\n",
    "\n",
    "    exp_c = {'kId': exp_c_kId, 'profile': exp_c_profile, 'fitness': exp_c_fitness}\n",
    "\n",
    "    return df_qId_HUDD, exp_c\n",
    "\n",
    "\n",
    "def prepare_data_cf(df_qId_HUDD, cols_dict):\n",
    "    # Convert data types\n",
    "    df_qId_HUDD_pre = df_qId_HUDD[cols_dict['cols_pred']].copy(deep=True) #.astype('int').copy(deep=True)\n",
    "    df_qId_HUDD_pre[cols_dict['cols_id']] = df_qId_HUDD[cols_dict['cols_id']]\n",
    "    #df_qId_HUDD_pre[cols_dict['categorical_features']].copy(deep=True) #.astype('int').copy(deep=True)\n",
    "    # df_qId_HUDD_pre[cols_dict['continuous_features']] = df_qId_HUDD[cols_dict['continuous_features']].astype(\n",
    "    #    'float').copy(deep=True)\n",
    "    df_qId_HUDD_pre[cols_dict['outcome_name_col']] = df_qId_HUDD[cols_dict['outcome_name_col']].copy(deep=True)\n",
    "    feature_dtypes = None # {col: df_qId_HUDD_pre[col].dtype for col in df_qId_HUDD_pre[cols_dict['cols_pred']].columns}\n",
    "\n",
    "    return df_qId_HUDD_pre, feature_dtypes\n",
    "\n",
    "\n",
    "def define_target(args, df_qId_HUDD):\n",
    "    # 'in_top_k' or 'out_top_k' depending on the candidate position\n",
    "    explicand_class = 'in_top_k' if args.candidate_position <= MacroVariables.TOP_K else 'out_top_k'\n",
    "\n",
    "    # target rank for counterfactual explanation\n",
    "    if args.target_rank:\n",
    "        tgt_cf_rank = args.target_rank\n",
    "        tgt_cf_score = df_qId_HUDD[df_qId_HUDD['pred_rank'] == tgt_cf_rank]['score'].iloc[0]\n",
    "        tgt_cf_candidate = df_qId_HUDD[df_qId_HUDD['pred_rank'] == tgt_cf_rank]\n",
    "\n",
    "    elif args.target_score:\n",
    "        tgt_cf_rank = None\n",
    "        tgt_cf_score = args.target_score\n",
    "        tgt_cf_candidate = None\n",
    "    else:\n",
    "        raise ValueError('Either target rank or target score must be provided')\n",
    "\n",
    "    return explicand_class, tgt_cf_rank, tgt_cf_score, tgt_cf_candidate\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:06:15.288667Z",
     "start_time": "2025-02-06T00:06:15.287523Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build the preprocessing pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def build_matching_functions():\n",
    "    # Matching functions for pairs of job-candidate features\n",
    "    maps_matching = {\n",
    "         # MatchBinary: 1 = job value = candidate value OR job value is 'Any' OR candidate value is 'Any', 0 = otherwise\n",
    "        # (('qId',), ('qId',)): IdentityMapping(),\n",
    "        # (('kId',), ('kId',)): IdentityMapping(),\n",
    "        # (('rank',), ('rank',)): IdentityMapping(),\n",
    "        (('Contract_j', 'Contract_c'), ('fitness_Contract',)): MatchBinary(),\n",
    "        (('Gender_j', 'Gender_c'), ('fitness_Gender',)): MatchBinary(),\n",
    "        (('Nationality_j', 'Nationality_c'), ('fitness_Nationality',)): MatchBinary(),\n",
    "\n",
    "         # MatchOrdinal: 1 = job value >= candidate OR job value is 'Any', 0 = otherwise\n",
    "        (('Education_j', 'Education_c'), ('fitness_Education',)): MatchOrdinal(),\n",
    "        (('Experience_j', 'Experience_c'), ('fitness_Experience',)): MatchOrdinal(),\n",
    "\n",
    "         # MatchFeatureInclusion: 1 = candidate value in (job value(0,), >= job value(1,)) OR job value is 'Any', 0 = otherwise\n",
    "        # (('Age_j', 'Age_c'), ('fitness_Age',)): MatchFeatureInclusion(),\n",
    "\n",
    "         # MatchFeatureSet: 1 = fraction of job value that appear in candidate value\n",
    "        (('Languages_j', 'Languages_c'), ('fitness_Languages',)): MatchFeatureSet(),\n",
    "        (('Competences_j', 'Competences_c'), ('fitness_Competences',)): MatchFeatureSet(),\n",
    "        (('Knowledge_j', 'Knowledge_c'), ('fitness_Knowledge',)): MatchFeatureSet()\n",
    "    }\n",
    "    return maps_matching\n",
    "\n",
    "\n",
    "def build_fitness_matrix(df_CDS_JDS, cols_dict, fair_data=True):\n",
    "    \"\"\"\n",
    "    Build the fitness matrix\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df_CDS_JDS: pd.DataFrame\n",
    "        The dataset CDS_JDS\n",
    "    cols_dict: dict\n",
    "        Dictionary with the columns of the HUDD dataset\n",
    "    fair_data: bool\n",
    "        Whether the data is fair or unfair\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    pipeline_fitness: sklearn.pipeline.Pipeline\n",
    "        The pipeline to calculate the fitness matrix\n",
    "    df_fitness_mat: pd.DataFrame\n",
    "        The fitness matrix\n",
    "    \"\"\"\n",
    "    maps_matching = build_matching_functions()\n",
    "\n",
    "    # Calculation as fit-transform preprocessing\n",
    "    pipeline_fitness = Pipeline(steps=[\n",
    "        (\"init\", AttachMetadata(md_CDS_JDS_ADS)),\n",
    "        (\"matching\", DerivedColumn(maps_matching)),\n",
    "        (\"end\", DetachMetadata())\n",
    "    ])\n",
    "\n",
    "    pipeline_fitness.fit(X=df_CDS_JDS)\n",
    "    fitness_matrix = pipeline_fitness.transform(X=df_CDS_JDS)\n",
    "    df_fitness_mat = fitness_matrix.copy(deep=True)\n",
    "    columns_keep = cols_dict['cols_id'] + \\\n",
    "                   [col for col in fitness_matrix if\n",
    "                    col.startswith('fitness_')] + cols_dict['cols_sensitive'] + cols_dict['col_target']\n",
    "\n",
    "    df_fitness_mat = df_fitness_mat[columns_keep]\n",
    "\n",
    "    # From scores, we can learn regressors; or we can produce ranks, and learn ranking models\n",
    "    df_fitness_mat['rank'] = df_fitness_mat.groupby(\"qId\")['score'].rank('dense', ascending=False)\n",
    "    df_fitness_mat['rank'] = df_fitness_mat['rank'].apply(lambda x: x if x <= MacroVariables.TOP_K else MacroVariables.TOP_K + 1)\n",
    "\n",
    "    return pipeline_fitness, df_fitness_mat\n",
    "\n",
    "\n",
    "def build_pipeline_fitness(df_CDS_JDS):\n",
    "    \"\"\"\n",
    "    Build the pipeline to calculate the fitness matrix\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df_CDS_JDS: pd.DataFrame\n",
    "        The dataset CDS_JDS\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    pipeline_fitness: sklearn.pipeline.Pipeline\n",
    "        The pipeline to calculate the fitness matrix\n",
    "    fitness_matrix: pd.DataFrame\n",
    "        The fitness matrix\n",
    "    cols_dict_FEDD: dict\n",
    "        Dictionary with the columns of the FEDD dataset\n",
    "    \"\"\"\n",
    "    maps_matching = build_matching_functions()\n",
    "\n",
    "    # Calculation as fit-transform preprocessing\n",
    "    pipeline_fitness = Pipeline(steps=[\n",
    "        (\"init\", AttachMetadata(md_CDS_JDS_ADS)),\n",
    "        (\"matching\", DerivedColumn(maps_matching)),\n",
    "        (\"end\", DetachMetadata())\n",
    "    ])\n",
    "\n",
    "    fitness_matrix = pipeline_fitness.fit_transform(X=df_CDS_JDS)\n",
    "\n",
    "\n",
    "    cols_dict_FEDD = define_cols_dict_FEDD()\n",
    "    return pipeline_fitness, fitness_matrix, cols_dict_FEDD\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:06:15.293161Z",
     "start_time": "2025-02-06T00:06:15.291823Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def transform_split(df_train_HUDD, df_val_HUDD, df_test_HUDD, pipeline_fitness, cols_dict_HUDD):\n",
    "    \"\"\"\n",
    "    Transform the HUDD datasets into FEDD datasets by applying the fitness pipeline\n",
    "\n",
    "    Parameters:\n",
    "    df_train_HUDD: pd.DataFrame\n",
    "        Training set of the HUDD dataset\n",
    "    df_val_HUDD: pd.DataFrame\n",
    "        Validation set of the HUDD dataset\n",
    "    df_test_HUDD: pd.DataFrame\n",
    "        Test set of the HUDD dataset\n",
    "    pipeline_fitness: sklearn.pipeline.Pipeline\n",
    "        Pipeline to calculate the fitness matrix\n",
    "    cols_dict_HUDD: dict\n",
    "        Dictionary with the columns of the HUDD dataset\n",
    "\n",
    "    Returns:\n",
    "    df_train_FEDD: pd.DataFrame\n",
    "        Training set of the FEDD dataset\n",
    "    df_val_FEDD: pd.DataFrame\n",
    "        Validation set of the FEDD dataset\n",
    "    df_test_FEDD: pd.DataFrame\n",
    "        Test set of the FEDD dataset\n",
    "    \"\"\"\n",
    "    df_train_FEDD = pipeline_fitness.transform(df_train_HUDD)\n",
    "    df_train_FEDD.reset_index(drop=True, inplace=True)\n",
    "    print('cols_dict_HUDD', cols_dict_HUDD)\n",
    "\n",
    "    df_train_FEDD[cols_dict_HUDD['cols_id']] = df_train_HUDD[cols_dict_HUDD['cols_id']].values\n",
    "    df_train_FEDD[cols_dict_HUDD['col_rank']] = df_train_HUDD[cols_dict_HUDD['col_rank']].values\n",
    "\n",
    "    df_val_FEDD = pipeline_fitness.transform(df_val_HUDD)\n",
    "    df_val_FEDD.reset_index(inplace=True)\n",
    "    df_val_FEDD[cols_dict_HUDD['cols_id']] = df_val_HUDD[cols_dict_HUDD['cols_id']].values\n",
    "    df_val_FEDD[cols_dict_HUDD['col_rank']] = df_val_HUDD[cols_dict_HUDD['col_rank']].values\n",
    "\n",
    "    df_test_FEDD = pipeline_fitness.transform(df_test_HUDD)\n",
    "    df_test_FEDD.reset_index(drop=True, inplace=True)\n",
    "    df_test_FEDD[cols_dict_HUDD['cols_id']] = df_test_HUDD[cols_dict_HUDD['cols_id']].values\n",
    "    df_test_FEDD[cols_dict_HUDD['col_rank']] = df_test_HUDD[cols_dict_HUDD['col_rank']].values\n",
    "\n",
    "    return df_train_FEDD, df_val_FEDD, df_test_FEDD"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:06:15.296406Z",
     "start_time": "2025-02-06T00:06:15.294880Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def train(ranker, df_train, df_val, cols_dict):\n",
    "    df_train_counts = df_train.groupby(\"qId\")[\"qId\"].count().to_numpy()\n",
    "    df_val_counts = df_val.groupby(\"qId\")[\"qId\"].count().to_numpy()\n",
    "\n",
    "    # Fitting ranker:\n",
    "    ranker.fit(\n",
    "        X=df_train[cols_dict['cols_pred']],\n",
    "        # LightGBM relevance is the higher the better\n",
    "        y=rank2relevance(df_train, MacroVariables.TOP_K, cols_dict['col_rank']),\n",
    "        group = df_train_counts,\n",
    "        eval_at = [MacroVariables.TOP_K],\n",
    "        # LightGBM relevance is the higher the better\n",
    "        eval_set =[(df_val[cols_dict['cols_pred']], rank2relevance(df_val, MacroVariables.TOP_K, cols_dict['col_rank']))],\n",
    "        eval_group =[df_val_counts]\n",
    "    )\n",
    "\n",
    "    return ranker\n",
    "\n",
    "\n",
    "def evaluate(ranker, df_eval, cols_dict):\n",
    "    df_test_counts = df_eval.groupby(\"qId\")[\"qId\"].count().to_numpy()\n",
    "    # Predicting ranker:\n",
    "    df_eval['lambda'] = ranker.predict(df_eval[cols_dict['cols_pred']])\n",
    "    df_eval['pred_rank'] = df_eval.groupby(\"qId\")['lambda'].rank('dense', ascending=False)\n",
    "    df_eval['pred_rank'] = df_eval['pred_rank'].apply(lambda x: x if x <= MacroVariables.TOP_K else MacroVariables.TOP_K + 1)\n",
    "\n",
    "    return df_eval\n",
    "\n",
    "\n",
    "def ranking_pipeline(df_train_FEDD, df_val_FEDD, df_test_FEDD, cols_dict_FEDD):\n",
    "    pipeline_fitness.transform(df_train_HUDD)\n",
    "    # Define the ranking model\n",
    "    ranker = LGBMRanker(\n",
    "        objective=\"lambdarank\",\n",
    "        class_weight=\"balanced\",\n",
    "        boosting_type=\"gbdt\",\n",
    "        importance_type=\"gain\",\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        force_row_wise=True,\n",
    "        n_jobs=-1,  # max parallelism\n",
    "        verbose=-1  # no verbosity\n",
    "    )\n",
    "\n",
    "    ranker = train(ranker, df_train_FEDD, df_val_FEDD, cols_dict_FEDD)\n",
    "    df_train_FEDD = evaluate(ranker, df_train_FEDD, cols_dict_FEDD)\n",
    "    df_val_FEDD = evaluate(ranker, df_val_FEDD, cols_dict_FEDD)\n",
    "    df_test_FEDD = evaluate(ranker, df_test_FEDD, cols_dict_FEDD)\n",
    "\n",
    "    return ranker, df_train_FEDD, df_val_FEDD, df_test_FEDD\n",
    "\n",
    "def attach_predictions(df_CDS_JDS, ranker, pipeline_fitness, cols_dict_FEDD):\n",
    "    df_CDS_JDS['lambda'] = ranker.predict(pipeline_fitness.transform(df_CDS_JDS)[cols_dict_FEDD['cols_pred']])\n",
    "    df_CDS_JDS['pred_rank'] = df_CDS_JDS.groupby(\"qId\")['lambda'].rank('dense', ascending=False)\n",
    "    return df_CDS_JDS"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:06:15.308912Z",
     "start_time": "2025-02-06T00:06:15.299144Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def define_explainer_HUDD(pipeline_fitness, ranker, df_qId_HUDD_pre, cols_dict_HUDD, cols_dict_FEDD, feature_dtypes, explanation_method):\n",
    "\n",
    "    super_pipeline_model = SuperRankerPipeline(pipeline_fitness, ranker, cols_dict_FEDD)\n",
    "\n",
    "    data_dice = dice_ml.Data(dataframe=df_qId_HUDD_pre[cols_dict_HUDD['cols_pred'] + [cols_dict_HUDD['outcome_name_col']]],\n",
    "                             continuous_features=cols_dict_HUDD['continuous_features'],\n",
    "                             categorical_features=cols_dict_HUDD['categorical_features'],\n",
    "                             setlist_features=cols_dict_HUDD['setlist_features'],\n",
    "                             outcome_name=cols_dict_HUDD['outcome_name_col'])\n",
    "\n",
    "    kwargs = {'top_k': MacroVariables.TOP_K, 'features_dtype': feature_dtypes}\n",
    "\n",
    "    model_dice = dice_ml.Model(model=super_pipeline_model,\n",
    "                               backend={'explainer': 'dice_xgboost.DiceGenetic',\n",
    "                                        'model': \"lgbmranker_pipeline_model.LGBMRankerPipelineModel\"},\n",
    "                               model_type=\"regressor\",\n",
    "                               # model_type=\"classifier\",\n",
    "                               kw_args=kwargs)\n",
    "\n",
    "    explainer = dice_ml.Dice(data_dice, model_dice, method=explanation_method)\n",
    "\n",
    "    return explainer, data_dice, model_dice\n",
    "\n",
    "\n",
    "def get_explanations_HUDD(df_qId_HUDD, exp_c, cols_dict_cf, explainer):\n",
    "    c_th_lambda = df_qId_HUDD[df_qId_HUDD['pred_rank'] == MacroVariables.TOP_K].iloc[0]['lambda']\n",
    "    explanations = explainer.generate_counterfactuals(exp_c['profile'][\n",
    "                                                          # cols_dict_cf['cols_id'] +\n",
    "                                                          cols_dict_cf['cols_pred']],\n",
    "                                                      total_CFs=10,\n",
    "                                                      desired_range=[c_th_lambda, 100],\n",
    "                                                      # desired_class=\"opposite\",\n",
    "                                                      verbose=True)\n",
    "    return explanations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:06:15.308987Z",
     "start_time": "2025-02-06T00:06:15.303754Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Hyperparameters for the explanation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# The job id for which the counterfactual explanation is to be generated'\n",
    "# Valid values 160-199\n",
    "job_id = 162\n",
    "\n",
    "# The position of the candidate in the ranked list\n",
    "candidate_position = 15\n",
    "\n",
    "# Alternative ways to define the target of the explanation\n",
    "target_rank = MacroVariables.TOP_K\n",
    "target_score = 0.9\n",
    "\n",
    "explanation_method = 'genetic'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:06:15.309021Z",
     "start_time": "2025-02-06T00:06:15.305476Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:06:18.000479Z",
     "start_time": "2025-02-06T00:06:15.308639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols_dict_HUDD {'outcome_name_col': 'lambda', 'continuous_features': ['Experience_c', 'Experience_j'], 'categorical_features': ['Education_c', 'Gender_c', 'Contract_c', 'Nationality_c', 'Education_j', 'Gender_j', 'Contract_j', 'Nationality_j'], 'setlist_features': ['Competences_c', 'Knowledge_c', 'Languages_c', 'Competences_j', 'Knowledge_j', 'Languages_j'], 'cols_pred': ['Education_c', 'Gender_c', 'Contract_c', 'Nationality_c', 'Competences_c', 'Knowledge_c', 'Languages_c', 'Experience_c', 'Education_j', 'Gender_j', 'Contract_j', 'Nationality_j', 'Competences_j', 'Knowledge_j', 'Languages_j', 'Experience_j'], 'cols_id': ['qId', 'kId'], 'cols_sensitive': ['Gender_c'], 'col_target': ['score'], 'col_rank': ['rank'], 'cols_pred_preprocess': ['Education_c', 'Age_c', 'Gender_c', 'Contract_c', 'Nationality_c', 'Competences_c', 'Knowledge_c', 'Languages_c', 'Experience_c', 'Education_j', 'Gender_j', 'Contract_j', 'Nationality_j', 'Competences_j', 'Knowledge_j', 'Languages_j', 'Experience_j'], 'cols_not_for_pred': ['Occupation_c', 'Occupation_j']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/preprocess/mapping.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[list(output_cols)] = X_new[list(output_cols)].values\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/preprocess/mapping.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[list(output_cols)] = X_new[list(output_cols)].values\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/preprocess/mapping.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[list(output_cols)] = X_new[list(output_cols)].values\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/preprocess/mapping.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[list(output_cols)] = X_new[list(output_cols)].values\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/preprocess/mapping.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[list(output_cols)] = X_new[list(output_cols)].values\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/preprocess/mapping.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[list(output_cols)] = X_new[list(output_cols)].values\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/preprocess/mapping.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[list(output_cols)] = X_new[list(output_cols)].values\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/preprocess/mapping.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[list(output_cols)] = X_new[list(output_cols)].values\n",
      "/var/folders/nc/fxn8v40951jf3zznr7vv6xx80000gn/T/ipykernel_69426/2022837698.py:13: UserWarning: {'explainer': 'dice_xgboost.DiceGenetic', 'model': 'lgbmranker_pipeline_model.LGBMRankerPipelineModel'} backend not in supported backends sklearn,TF1,TF2,PYT\n",
      "  model_dice = dice_ml.Model(model=super_pipeline_model,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counterfactual Explanations:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n",
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:300: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  query_instance_df_dummies[col] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing initial parameters to the genetic algorithm...\n",
      "Initialization complete! Generating counterfactuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mastropi/postdoc_works/xai_findhr/code/findhrAPI/src/findhr/xai/counterfactual/dice_ml/explainer_interfaces/dice_genetic.py:82: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  feature_weights_list.append(round(1 / self.feature_range[feature].max(), 2))\n",
      "100%|| 1/1 [00:01<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diverse Counterfactuals found! total time taken: 00 min 01 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = namedtuple('Args', ['target_rank', 'target_score', 'target_candidate'])\n",
    "\n",
    "args.target_rank = target_rank\n",
    "args.target_score = target_score\n",
    "args.candidate_position = candidate_position\n",
    "\n",
    "df_CDS_JDS, cols_dict_HUDD = load_dataset(fair_data=MacroVariables.FAIR_DATA)\n",
    "pipeline_fitness, df_fitness_mat, cols_dict_FEDD = build_pipeline_fitness(df_CDS_JDS)\n",
    "df_train_HUDD, df_val_HUDD, df_test_HUDD = data_split(df_CDS_JDS)\n",
    "df_train_FEDD, df_val_FEDD, df_test_FEDD = transform_split(df_train_HUDD, df_val_HUDD, df_test_HUDD, pipeline_fitness, cols_dict_HUDD)\n",
    "\n",
    "ranker, df_train_FEDD, df_val_FEDD, df_test_FEDD = ranking_pipeline(df_train_FEDD, df_val_FEDD, df_test_FEDD, cols_dict_FEDD)\n",
    "df_CDS_JDS = attach_predictions(df_CDS_JDS, ranker, pipeline_fitness, cols_dict_FEDD)\n",
    "\n",
    "df_qId_HUDD, exp_c,  = extract_explicand_data_cf(job_id=job_id, exp_c_pred_rank=args.candidate_position,\n",
    "                                                 pipeline_fitness=pipeline_fitness, df_CDS_JDS=df_CDS_JDS)\n",
    "\n",
    "df_qId_HUDD_pre, feature_dtypes = prepare_data_cf(df_qId_HUDD, cols_dict_HUDD)\n",
    "\n",
    "explicand_class, tgt_cf_rank, tgt_cf_score, tgt_cf_candidate = define_target(args, df_qId_HUDD)\n",
    "\n",
    "explainer, data_dice, model_dice = define_explainer_HUDD(pipeline_fitness, ranker, df_qId_HUDD_pre,\n",
    "                                                         cols_dict_HUDD, cols_dict_FEDD, feature_dtypes,\n",
    "                                                         explanation_method=explanation_method)\n",
    "\n",
    "print('Counterfactual Explanations:')\n",
    "explanations_HUDD = get_explanations_HUDD(df_qId_HUDD, exp_c, cols_dict_HUDD, explainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['qId', 'kId', 'Occupation_c', 'Education_c', 'Gender_c', 'Contract_c',\n       'Nationality_c', 'Competences_c', 'Knowledge_c', 'Languages_c',\n       'Experience_c', 'Occupation_j', 'Education_j', 'Gender_j', 'Contract_j',\n       'Nationality_j', 'Competences_j', 'Knowledge_j', 'Languages_j',\n       'Experience_j', 'score', 'rank', 'fitness_Contract', 'fitness_Gender',\n       'fitness_Nationality', 'fitness_Education', 'fitness_Experience',\n       'fitness_Languages', 'fitness_Competences', 'fitness_Knowledge',\n       'lambda', 'pred_rank'],\n      dtype='object')"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CDS_JDS.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:06:18.004812Z",
     "start_time": "2025-02-06T00:06:18.002125Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# final_cfs_df = pd.read_csv('final_cfs_df_HUDD.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:06:18.006613Z",
     "start_time": "2025-02-06T00:06:18.004345Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# final_cfs_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:06:18.008393Z",
     "start_time": "2025-02-06T00:06:18.006665Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# exp_c_profile = pd.read_csv('prof.csv', index_col=0)\n",
    "# exp_c_profile"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:06:18.010702Z",
     "start_time": "2025-02-06T00:06:18.008474Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query instance (original outcome : -3.6078786849975586)\n"
     ]
    },
    {
     "data": {
      "text/plain": "    Education_c    Gender_c Contract_c Nationality_c  \\\n0  No education  Non-binary     Hybrid       Spanish   \n\n                                       Competences_c  \\\n0  (operate vessel engine room, prepare equipment...   \n\n                                  Knowledge_c Languages_c  Experience_c  \\\n0  (inland waterway ship building, mechanics)          ()             1   \n\n  Education_j Gender_j Contract_j Nationality_j  \\\n0         Any      Any     Remote           Any   \n\n                                       Competences_j  \\\n0  (operate vessel engine room, manage vessel con...   \n\n                                         Knowledge_j Languages_j  \\\n0  (mechanics, inland waterway ship building, eng...          ()   \n\n   Experience_j    lambda  \n0             1 -3.607879  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Education_c</th>\n      <th>Gender_c</th>\n      <th>Contract_c</th>\n      <th>Nationality_c</th>\n      <th>Competences_c</th>\n      <th>Knowledge_c</th>\n      <th>Languages_c</th>\n      <th>Experience_c</th>\n      <th>Education_j</th>\n      <th>Gender_j</th>\n      <th>Contract_j</th>\n      <th>Nationality_j</th>\n      <th>Competences_j</th>\n      <th>Knowledge_j</th>\n      <th>Languages_j</th>\n      <th>Experience_j</th>\n      <th>lambda</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>No education</td>\n      <td>Non-binary</td>\n      <td>Hybrid</td>\n      <td>Spanish</td>\n      <td>(operate vessel engine room, prepare equipment...</td>\n      <td>(inland waterway ship building, mechanics)</td>\n      <td>()</td>\n      <td>1</td>\n      <td>Any</td>\n      <td>Any</td>\n      <td>Remote</td>\n      <td>Any</td>\n      <td>(operate vessel engine room, manage vessel con...</td>\n      <td>(mechanics, inland waterway ship building, eng...</td>\n      <td>()</td>\n      <td>1</td>\n      <td>-3.607879</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diverse Counterfactual set (new outcome: [-2.557599669093543, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": "    Education_c    Gender_c   Contract_c Nationality_c  \\\n0  No education  Non-binary       Remote       Spanish   \n0  No education  Non-binary  In presence       Spanish   \n0  No education  Non-binary       Hybrid        French   \n0  No education  Non-binary       Hybrid     LowGerman   \n0  No education  Non-binary       Hybrid       Italian   \n0  No education  Non-binary       Hybrid       English   \n0  No education  Non-binary       Hybrid     LowGerman   \n0   Bachelor D.  Non-binary       Hybrid       Spanish   \n0  No education  Non-binary       Hybrid     LowGerman   \n0  No education  Non-binary       Hybrid       Catalan   \n\n                                       Competences_c  \\\n0  (evaluate engine performance, moor vessels, ma...   \n0  (moor vessels, manage vessel control systems, ...   \n0  (manage vessel control systems, prepare engine...   \n0  (manage vessel control systems, maintain recor...   \n0  (manage vessel control systems, maintain recor...   \n0  (manage vessel control systems, prepare engine...   \n0  (detect malfunctions in engines, operate vesse...   \n0  (prepare equipment for navigation operations, ...   \n0  (detect malfunctions in engines, operate vesse...   \n0  (prepare equipment for navigation operations, ...   \n\n                                         Knowledge_c Languages_c  \\\n0  (principles of cargo stowage, engine component...          ()   \n0  (toxicology, microbiology-bacteriology, human ...          ()   \n0  (mechanics of vessels, european classification...          ()   \n0  (quality assurance procedures, quality standards)          ()   \n0  (spelling, practical lexicography, semantics, ...          ()   \n0  (principles of mechanical engineering, electro...          ()   \n0  (engine components, mechanics, mechanics of ve...          ()   \n0  (mechanics, mechanics of vessels, electronics,...          ()   \n0  (quality assurance procedures, quality standards)          ()   \n0  (human resource management, personnel manageme...          ()   \n\n   Experience_c Education_j Gender_j Contract_j Nationality_j  \\\n0             1         Any      Any     Remote           Any   \n0             1         Any      Any     Remote           Any   \n0             1         Any      Any     Remote           Any   \n0             1         Any      Any     Remote           Any   \n0             1         Any      Any     Remote           Any   \n0             1         Any      Any     Remote           Any   \n0             1         Any      Any     Remote           Any   \n0             1         Any      Any     Remote           Any   \n0             1         Any      Any     Remote           Any   \n0             1         Any      Any     Remote           Any   \n\n                                       Competences_j  \\\n0  (manage vessel control systems, operate vessel...   \n0  (manage vessel control systems, operate vessel...   \n0  (manage vessel control systems, operate vessel...   \n0  (manage vessel control systems, operate vessel...   \n0  (manage vessel control systems, operate vessel...   \n0  (manage vessel control systems, operate vessel...   \n0  (manage vessel control systems, operate vessel...   \n0  (manage vessel control systems, operate vessel...   \n0  (manage vessel control systems, operate vessel...   \n0  (manage vessel control systems, operate vessel...   \n\n                                         Knowledge_j Languages_j  \\\n0  (inland waterway ship building, engine compone...          ()   \n0  (inland waterway ship building, engine compone...          ()   \n0  (inland waterway ship building, engine compone...          ()   \n0  (inland waterway ship building, engine compone...          ()   \n0  (inland waterway ship building, engine compone...          ()   \n0  (inland waterway ship building, engine compone...          ()   \n0  (inland waterway ship building, engine compone...          ()   \n0  (inland waterway ship building, engine compone...          ()   \n0  (inland waterway ship building, engine compone...          ()   \n0  (inland waterway ship building, engine compone...          ()   \n\n   Experience_j    lambda  \n0             1 -0.717933  \n0             1 -2.166180  \n0             1 -1.418754  \n0             1 -2.166180  \n0             1 -2.166180  \n0             1 -2.208929  \n0             1 -1.251019  \n0             1 -1.418754  \n0             1 -2.166180  \n0             1 -2.166180  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Education_c</th>\n      <th>Gender_c</th>\n      <th>Contract_c</th>\n      <th>Nationality_c</th>\n      <th>Competences_c</th>\n      <th>Knowledge_c</th>\n      <th>Languages_c</th>\n      <th>Experience_c</th>\n      <th>Education_j</th>\n      <th>Gender_j</th>\n      <th>Contract_j</th>\n      <th>Nationality_j</th>\n      <th>Competences_j</th>\n      <th>Knowledge_j</th>\n      <th>Languages_j</th>\n      <th>Experience_j</th>\n      <th>lambda</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>No education</td>\n      <td>Non-binary</td>\n      <td>Remote</td>\n      <td>Spanish</td>\n      <td>(evaluate engine performance, moor vessels, ma...</td>\n      <td>(principles of cargo stowage, engine component...</td>\n      <td>()</td>\n      <td>1</td>\n      <td>Any</td>\n      <td>Any</td>\n      <td>Remote</td>\n      <td>Any</td>\n      <td>(manage vessel control systems, operate vessel...</td>\n      <td>(inland waterway ship building, engine compone...</td>\n      <td>()</td>\n      <td>1</td>\n      <td>-0.717933</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>No education</td>\n      <td>Non-binary</td>\n      <td>In presence</td>\n      <td>Spanish</td>\n      <td>(moor vessels, manage vessel control systems, ...</td>\n      <td>(toxicology, microbiology-bacteriology, human ...</td>\n      <td>()</td>\n      <td>1</td>\n      <td>Any</td>\n      <td>Any</td>\n      <td>Remote</td>\n      <td>Any</td>\n      <td>(manage vessel control systems, operate vessel...</td>\n      <td>(inland waterway ship building, engine compone...</td>\n      <td>()</td>\n      <td>1</td>\n      <td>-2.166180</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>No education</td>\n      <td>Non-binary</td>\n      <td>Hybrid</td>\n      <td>French</td>\n      <td>(manage vessel control systems, prepare engine...</td>\n      <td>(mechanics of vessels, european classification...</td>\n      <td>()</td>\n      <td>1</td>\n      <td>Any</td>\n      <td>Any</td>\n      <td>Remote</td>\n      <td>Any</td>\n      <td>(manage vessel control systems, operate vessel...</td>\n      <td>(inland waterway ship building, engine compone...</td>\n      <td>()</td>\n      <td>1</td>\n      <td>-1.418754</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>No education</td>\n      <td>Non-binary</td>\n      <td>Hybrid</td>\n      <td>LowGerman</td>\n      <td>(manage vessel control systems, maintain recor...</td>\n      <td>(quality assurance procedures, quality standards)</td>\n      <td>()</td>\n      <td>1</td>\n      <td>Any</td>\n      <td>Any</td>\n      <td>Remote</td>\n      <td>Any</td>\n      <td>(manage vessel control systems, operate vessel...</td>\n      <td>(inland waterway ship building, engine compone...</td>\n      <td>()</td>\n      <td>1</td>\n      <td>-2.166180</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>No education</td>\n      <td>Non-binary</td>\n      <td>Hybrid</td>\n      <td>Italian</td>\n      <td>(manage vessel control systems, maintain recor...</td>\n      <td>(spelling, practical lexicography, semantics, ...</td>\n      <td>()</td>\n      <td>1</td>\n      <td>Any</td>\n      <td>Any</td>\n      <td>Remote</td>\n      <td>Any</td>\n      <td>(manage vessel control systems, operate vessel...</td>\n      <td>(inland waterway ship building, engine compone...</td>\n      <td>()</td>\n      <td>1</td>\n      <td>-2.166180</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>No education</td>\n      <td>Non-binary</td>\n      <td>Hybrid</td>\n      <td>English</td>\n      <td>(manage vessel control systems, prepare engine...</td>\n      <td>(principles of mechanical engineering, electro...</td>\n      <td>()</td>\n      <td>1</td>\n      <td>Any</td>\n      <td>Any</td>\n      <td>Remote</td>\n      <td>Any</td>\n      <td>(manage vessel control systems, operate vessel...</td>\n      <td>(inland waterway ship building, engine compone...</td>\n      <td>()</td>\n      <td>1</td>\n      <td>-2.208929</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>No education</td>\n      <td>Non-binary</td>\n      <td>Hybrid</td>\n      <td>LowGerman</td>\n      <td>(detect malfunctions in engines, operate vesse...</td>\n      <td>(engine components, mechanics, mechanics of ve...</td>\n      <td>()</td>\n      <td>1</td>\n      <td>Any</td>\n      <td>Any</td>\n      <td>Remote</td>\n      <td>Any</td>\n      <td>(manage vessel control systems, operate vessel...</td>\n      <td>(inland waterway ship building, engine compone...</td>\n      <td>()</td>\n      <td>1</td>\n      <td>-1.251019</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Bachelor D.</td>\n      <td>Non-binary</td>\n      <td>Hybrid</td>\n      <td>Spanish</td>\n      <td>(prepare equipment for navigation operations, ...</td>\n      <td>(mechanics, mechanics of vessels, electronics,...</td>\n      <td>()</td>\n      <td>1</td>\n      <td>Any</td>\n      <td>Any</td>\n      <td>Remote</td>\n      <td>Any</td>\n      <td>(manage vessel control systems, operate vessel...</td>\n      <td>(inland waterway ship building, engine compone...</td>\n      <td>()</td>\n      <td>1</td>\n      <td>-1.418754</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>No education</td>\n      <td>Non-binary</td>\n      <td>Hybrid</td>\n      <td>LowGerman</td>\n      <td>(detect malfunctions in engines, operate vesse...</td>\n      <td>(quality assurance procedures, quality standards)</td>\n      <td>()</td>\n      <td>1</td>\n      <td>Any</td>\n      <td>Any</td>\n      <td>Remote</td>\n      <td>Any</td>\n      <td>(manage vessel control systems, operate vessel...</td>\n      <td>(inland waterway ship building, engine compone...</td>\n      <td>()</td>\n      <td>1</td>\n      <td>-2.166180</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>No education</td>\n      <td>Non-binary</td>\n      <td>Hybrid</td>\n      <td>Catalan</td>\n      <td>(prepare equipment for navigation operations, ...</td>\n      <td>(human resource management, personnel manageme...</td>\n      <td>()</td>\n      <td>1</td>\n      <td>Any</td>\n      <td>Any</td>\n      <td>Remote</td>\n      <td>Any</td>\n      <td>(manage vessel control systems, operate vessel...</td>\n      <td>(inland waterway ship building, engine compone...</td>\n      <td>()</td>\n      <td>1</td>\n      <td>-2.166180</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(explanations_HUDD.visualize_as_dataframe())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T00:06:18.059570Z",
     "start_time": "2025-02-06T00:06:18.010488Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
